---

- hosts: >
    {{ idr_environment | default('idr') }}-dockermanager-hosts

  pre_tasks:
  - name: Get NFS IP
    set_fact:
      docker_nfs_host_ansible: >-
        {{
          hostvars[groups[
            idr_environment | default('idr') + '-dockermanager-hosts'][0]]
            ['ansible_' + (idr_net_iface | default('eth0'))]['ipv4']['address']
        }}


  roles:
    - role: kubernetes
      kubernetes_role: master
      kubernetes_advertise_address: >-
        {{ hostvars[groups[idr_environment | default('idr') +
           '-dockermanager-hosts'][0]]['ansible_' +
           (idr_net_iface | default('eth0'))]['ipv4']['address']
        }}

  tasks:

  - name: Create kubernetes spec directory
    become: yes
    file:
      path: "{{ item }}"
      state: directory
    with_items:
    - /opt/kubernetes-spec
    - /opt/kubernetes-spec/nfs-volume-provisioner
    - /opt/kubernetes-spec/jupyterhub
    - /opt/kubernetes-spec/mineotaur

  - name: Copy kubernetes spec files
    become: yes
    copy:
      src: kubernetes-spec/{{ item }}
      dest: /opt/kubernetes-spec/{{ item }}
    with_items:
    - nfs-volume-provisioner/clusterrole.yaml
    - nfs-volume-provisioner/clusterrolebinding.yaml
    - nfs-volume-provisioner/serviceaccount.yaml
    - nfs-volume-provisioner/deployment.yaml
    - nfs-volume-provisioner/class.yaml

    #- jupyterhub/config-example.yml
    # Requires the hash of the config file (see later tasks)
    #- jupyterhub/deployment.yml

    - mineotaur/deployment.yml

  # TODO: This currently requires private vars and will fail without them.
  # Defaults should be provided to allow public deployment
  - name: Copy kubernetes spec templates
    become: yes
    template:
      src: kubernetes-spec/{{ item }}
      dest: /opt/kubernetes-spec/{{ item }}
    with_items:
    - jupyterhub/nfsvolume.yml
    - jupyterhub/config.yml
    - mineotaur/nfsvolume.yml

  # `kubectl apply` automaticallty restarts deployments if the spec
  # changes, but not if a ConfigMap changes.
  # We can force an update by including a hash of the config file in the
  # deployment spec: https://stackoverflow.com/q/37317003
  # Related issue: https://github.com/kubernetes/kubernetes/issues/22368
  - name: Hash kubernetes configuration files
    stat:
      path: /opt/kubernetes-spec/jupyterhub/config.yml
    register: _kubernetes_jupyterhub_config_st

  - name: Get kubernetes jupyterhub config hash
    set_fact:
      kubernetes_jupyterhub_config_hash: "{{ _kubernetes_jupyterhub_config_st.stat.checksum }}"

  - name: Copy kubernetes jupyterhub spec templates
    become: yes
    template:
      # Requires kubernetes_jupyterhub_config_hash
      src: kubernetes-spec/jupyterhub/deployment.yml
      dest: /opt/kubernetes-spec/jupyterhub/deployment.yml


- hosts: >
    {{ idr_environment | default('idr') }}-dockerworker-hosts
  roles:
    - role: kubernetes
      kubernetes_role: worker
      kubernetes_token: >-
        {{ hostvars[groups[idr_environment | default('idr') +
           '-dockermanager-hosts'][0]].kubernetes_token
        }}
      kubernetes_master: >
        {{ hostvars[groups[idr_environment | default('idr') +
           '-dockermanager-hosts'][0]]['ansible_' +
           (idr_net_iface | default('eth0'))]['ipv4']['address']
        }}:6443

# Now run:
# kubectl get nodes
# kubectl apply -f jupyterhub-config.yml -f jupyterhub-deployment.yml
# kubectl logs -f deployment/jupyterhub-deployment
