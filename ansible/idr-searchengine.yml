# Configure Search engine +  run Elasticsearch nodes

- hosts: "{{ idr_environment | default('idr') }}-database-hosts"

- name: Deploying search engine
  hosts: "{{ idr_environment | default('idr') }}-searchengine-hosts"
  vars:
    elasticsearch_nodes: [ ]

  tasks:
  - name: Get database host
    set_fact:
      database_server_url: >-
        {{
          hostvars[groups[idr_environment | default('idr') + '-database-hosts'][0]]
          ['ansible_' + (idr_net_iface | default('eth0'))]['ipv4']['address']
        }}

  - name: Create app top level directory
    become: yes
    file:
      path: "{{ apps_folder }}/searchengine"
      recurse: yes
      state: directory
      owner: root
      group: root
      mode: 0755

  - name: Create searchengine folder directory
    become: yes
    file:
      path: "{{ apps_folder }}/searchengine/searchengine"
      recurse: yes
      state: directory
      owner: root
      group: root
      mode: 0755

  - name: Create searchengine logs directory
    become: yes
    file:
      path: "{{ apps_folder }}/searchengine/searchengine/logs"
      state: directory
      mode: 0755

  - name: Create searchengine cached directory
    become: yes
    file:
      path: "{{ apps_folder }}/searchengine/searchengine/cacheddata"
      state: directory
      mode: 0755

  - name: Create elasticsearch directory
    become: yes
    file:
      path: "{{ apps_folder }}/searchengine/elasticsearch"
      state: directory
      # User id in elasticsearch Docker image
      owner: 1000
      group: root
      mode: 0755

  - name: Create elasticsearch main nodes directories
    become: yes
    file:
      path: "{{ apps_folder }}/searchengine/elasticsearch/node{{ item }}"
      state: directory
      # User id in elasticsearch Docker image
      owner: 1000
      group: root
      mode: 0755
    with_sequence: start=1 count={{ elasticsearch_no_nodes }}

  - name: Create elasticsearch logs directory
    become: yes
    file:
      path: "{{ apps_folder }}/searchengine/elasticsearch/node{{ item }}/logs"
      state: directory
      # User id in elasticsearch Docker image
      owner: 1000
      group: root
      mode: 0755
    with_sequence: start=1 count={{ elasticsearch_no_nodes }}

  - name: Create elasticsearch data directory
    become: yes
    file:
      path: "{{ apps_folder }}/searchengine/elasticsearch/node{{ item }}/data"
      state: directory
      # User id in elasticsearch Docker image
      owner: 1000
      group: root
      mode: 0755
    with_sequence: start=1 count={{ elasticsearch_no_nodes }}

  - name: Create ELasticsearch backup folder
    become: yes
    file:
      path: "{{ elasticsearch_backup_folder }}"
      recurse: yes
      state: directory
      owner: 1000
      group: root
      mode: 0755

  #Add all elasticsearch nodes
  - name: Add elastic nodes to elasticsearch_nodes
    set_fact:
      elasticsearch_nodes: '{{ elasticsearch_nodes + ["searchengine_elasticsearch_node"+item] }}'
    with_sequence: start=1 count={{ elasticsearch_no_nodes }}

  - name: Create docker network
    become: yes
    docker_network:
      name: searchengine-net
      ipam_config:
        - subnet=10.11.0.0/16

  # I got some memory exceptions when start using elasticsearch cluster and
  # increasing the mmap counts limits fix this issue
  #https://www.elastic.co/guide/en/elasticsearch/reference/7.16 /vm-max-map-count.html
  - name: set vm.max_map_count to 262144 in sysctl
    become: yes
    sysctl: name={{ item.varname }} value={{ item.varvalue }}
    with_items:
      - { varname: "vm.max_map_count", varvalue: "262144" }

  - name: Run first docker elasticsearch main node
    become: yes
    docker_container:
      image: "{{ search_engineelasticsearch_docker_image }}"
      name: "searchengine_elasticsearch_node1"
      cleanup: True
      ulimits:
        - 'memlock:-1:-1'
      env:
        path.data: "/var/lib/elasticsearch"
        path.logs: "/var/log/elasticsearch"
        path.repo: "{{ elasticsearch_backup_folder }}"
        node.name: searchengine_elasticsearch_node1
        bootstrap.memory_lock: "true"
        network.host: 0.0.0.0
        cluster.name: searchengine-cluster
        cluster.initial_master_nodes: "{{ elasticsearch_nodes | join(',') }}"
        http.host: 0.0.0.0
        #http.port: 9200
        ES_JAVA_OPTS: "-Xms2g -Xmx2g"
        ingest.geoip.downloader.enabled: "false"
      networks:
      - name: "searchengine-net"
      published_ports:
        - "9201:9200"
        - "9301:9300"
      state: started
      restart_policy: always
      volumes:
      - "{{ apps_folder }}/searchengine/elasticsearch/node1/data:/var/lib/elasticsearch"
      - "{{ apps_folder }}/searchengine/elasticsearch/node1/logs:/var/log/elasticsearch"
      - "{{ elasticsearch_backup_folder }}:{{ elasticsearch_backup_folder }}"

  - name: Run docker elasticsearch for the remaining nodes
    become: yes
    docker_container:
      image: "{{ search_engineelasticsearch_docker_image }}"
      name: "searchengine_elasticsearch_node{{ item }}"
      ulimits:
        - 'memlock:-1:-1'
      cleanup: True
      env:
        path.data: "/var/lib/elasticsearch"
        path.logs: "/var/log/elasticsearch"
        path.repo: "{{ elasticsearch_backup_folder }}"
        node.name: "searchengine_elasticsearch_node{{ item }}"
        bootstrap.memory_lock: "true"
        network.host: 0.0.0.0
        cluster.name: "searchengine-cluster"
        discovery.seed_hosts: "searchengine_elasticsearch_node1"
        cluster.initial_master_nodes: "{{ elasticsearch_nodes | join(',') }}"
        http.host: 0.0.0.0
        #http.port: 9200
        ES_JAVA_OPTS: "-Xms1g -Xmx1g"
        ingest.geoip.downloader.enabled: "false"

      networks:
      - name: "searchengine-net"
      published_ports:
        - "920{{ item }}:9200"
        - "930{{ item }}:9300"
      state: started
      restart_policy: always
      volumes:
      - "{{ apps_folder }}/searchengine/elasticsearch/node{{ item }}/data:/var/lib/elasticsearch"
      - "{{ apps_folder }}/searchengine/elasticsearch/node{{ item }}/logs:/var/log/elasticsearch"
      - "{{ elasticsearch_backup_folder }}:{{ elasticsearch_backup_folder }}"
    with_sequence: start=2 count={{ elasticsearch_no_nodes | int -1 }}

  - name: configure elasticsearch  for docker searchengine
    become: yes
    docker_container:
      image: "{{ searchengine_docker_image }}"
      name: searchengine_elasticsearch
      cleanup: True
      command: "set_elasticsearch_backup_folder -b {{ elasticsearch_backup_folder }}"
      state: started
      volumes:
      - "{{ apps_folder }}/searchengine/searchengine/:/etc/searchengine/"
      -
  - name: configure elasticsearch  for docker searchengine
    become: yes
    docker_container:
      image: "{{ searchengine_docker_image }}"
      name: searchengine_elasticsearch
      cleanup: True
      command: "set_elasticsearch_configuration -e {{ elasticsearch_nodes | join(',') }}"
      state: started
      volumes:
        - "{{ apps_folder }}/searchengine/searchengine/:/etc/searchengine/"


  - name: configure database for docker searchengine
    become: yes
    docker_container:
      image: "{{ searchengine_docker_image }}"
      name: searchengine_database
      cleanup: True
      #auto_remove: yes
      command: >
        set_database_configuration -u {{ database_server_url }}
        -d {{ database_name }} -s {{ database_port }} -n {{ database_username }} -p {{ database_user_password }}
      #networks:
      #- name: searchengine-net
      #published_ports:
      #- "5577:5577"
      state: started
      volumes:
      - "{{ apps_folder }}/searchengine/searchengine/:/etc/searchengine/"

  - name: configure IDR_TEST_FILE_URL item
    become: yes
    docker_container:
      image: "{{ searchengine_docker_image }}"
      name: searchengine_IDR_TEST_FILE
      cleanup: True
      command: "set_idr_test_file -i {{ IDR_TEST_FILE_URL }}"
      state: started
      volumes:
      - "{{ apps_folder }}/searchengine/searchengine/:/etc/searchengine/"


  - name: configure cache folder  for docker searchengine
    become: yes
    docker_container:
      image: "{{ searchengine_docker_image }}"
      name: searchengine_cache
      cleanup: True
      #auto_remove: yes
      command: "set_cache_folder -c /etc/searchengine/cachedata"
      #networks:
      #- name: searchengine-net
      #published_ports:
      #- "5577:5577"
      state: started
      volumes:
      - "{{ apps_folder }}/searchengine/searchengine/:/etc/searchengine/"

  - name: configure number of cache rows for docker searchengine
    become: yes
    docker_container:
      image: "{{ searchengine_docker_image }}"
      name: searchengine_cache
      cleanup: True
      #auto_remove: yes
      command: "set_cache_rows_number -n {{ cache_rows }}"
      state: started
      volumes:
      - "{{ apps_folder }}/searchengine/searchengine/:/etc/searchengine/"

  - name: configure secret key for docker searchengine
    become: yes
    docker_container:
      image: "{{ searchengine_docker_image }}"
      name: searchengine_cache
      cleanup: True
      #auto_remove: yes
      command: "set_searchengine_secret_key -s {{ searchengine_secret_key }}"
      state: started
      volumes:
      - "{{ apps_folder }}/searchengine/searchengine/:/etc/searchengine/"

  - name: create elasticsearch all indcies for docker searchengine
    become: yes
    docker_container:
      image: "{{ searchengine_docker_image }}"
      name: searchengine_create_index
      cleanup: True
      #auto_remove: yes
      command: create_index
      networks:
      - name: searchengine-net
      #published_ports:
      #- "5577:5577"
      state: started
      volumes:
      - "{{ apps_folder }}/searchengine/searchengine/:/etc/searchengine/"
